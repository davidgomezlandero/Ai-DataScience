# Multilayer Perceptron (In Progress)

## ðŸŽ¯ Problem Statement

Early detection of breast cancer is crucial for patient survival rates. This project implements a neural network from scratch to classify breast cancer tumors as **malignant or benign** based on diagnostic features extracted from digitized cell nucleus images.

**The Challenge**: Given 30 features from cell nuclei measurements, build a model that can accurately predict whether a tumor is malignant (dangerous) or benign (non-cancerous) with high precision to minimize false negatives.

## ðŸ“‹ Project Overview

This project involves implementing a multilayer perceptron neural network entirely from scratch to solve a binary classification problem. The focus is on understanding the mathematical foundations of neural networks: forward propagation, backpropagation, and gradient-based optimization.

## ðŸ“Š Dataset

**Breast Cancer Wisconsin (Diagnostic) Dataset**

- **Purpose**: Classify tumors as Malignant (M) or Benign (B)
- **Samples**: ~569 medical records
- **Features**: 30 continuous numeric values derived from cell nucleus images
- **Classes**: Binary (2 classes)

### Feature Categories
Features include measurements like:
- Radius, texture, perimeter, area
- Smoothness, compactness, concavity
- Symmetry, fractal dimension
- Statistical variations (mean, standard error, worst)

### Example Data Format
```
ID,Diagnosis,Feature1,Feature2,...,Feature30
8712766,M,17.47,24.68,116.1,984.6,0.1049,...,0.093
89382602,B,12.76,13.37,82.29,504.1,0.08794,...,0.08253
```

## ðŸ§  What This Project Teaches

### Core Concepts Implemented

1. **Neural Network Architecture**
   - Multi-layer perceptron design
   - Configurable hidden layers and neurons
   - Different activation functions

2. **Forward Propagation**
   - Matrix operations for data flow
   - Activation function applications
   - Output prediction generation

3. **Backpropagation Algorithm**
   - Gradient computation using chain rule
   - Error flow backward through layers
   - Weight and bias updates

4. **Optimization**
   - Stochastic Gradient Descent (SGD)
   - Learning rate effects
   - Convergence monitoring

5. **Data Preprocessing**
   - Feature normalization
   - Train-test splitting
   - Handling data imbalance

## ðŸ—ï¸ Project Structure

```
multilayer_perceptron/
â”œâ”€â”€ README.md                    # Project documentation
â”œâ”€â”€ data.csv                     # Breast cancer dataset
â”œâ”€â”€ multilayer_perceptron.py     # Core MLP implementation
â”œâ”€â”€ utils.py                     # Helper functions
â”œâ”€â”€ train.py                     # Training pipeline
â””â”€â”€ predict.py                   # Inference script
```

## ðŸŽ“ Learning Outcomes

By the end of this project, you will understand:

- âœ… How neural networks learn through backpropagation
- âœ… The mathematical foundations of deep learning
- âœ… How to normalize and preprocess medical data
- âœ… Trade-offs between model complexity and generalization
- âœ… How to evaluate classification models in healthcare context
- âœ… Why high recall is critical in medical diagnosis (minimize false negatives)

## ðŸš€ Implementation Status

### Phase 1: Foundation (Current)
- [x] Data loading and exploration
- [ ] Data preprocessing and normalization
- [ ] Neural network architecture design

### Phase 2: Core Algorithm
- [ ] Forward propagation implementation
- [ ] Activation functions (ReLU, Sigmoid, Tanh)
- [ ] Loss function (Binary Cross-Entropy)

### Phase 3: Training
- [ ] Backpropagation algorithm
- [ ] Gradient descent optimization
- [ ] Training loop with convergence

### Phase 4: Evaluation
- [ ] Model evaluation metrics (Accuracy, Precision, Recall, F1)
- [ ] Confusion matrix analysis
- [ ] Hyperparameter tuning

### Phase 5: Documentation
- [ ] Code documentation
- [ ] Mathematical explanations
- [ ] Usage examples

## ðŸ”§ Architecture Overview

```
Input Layer
(30 features from cell measurements)
        â†“
Hidden Layer 1 (e.g., 64 neurons, ReLU)
        â†“
Hidden Layer 2 (e.g., 32 neurons, ReLU)
        â†“
Output Layer (1 neuron, Sigmoid)
        â†“
Binary Classification: Malignant or Benign
```

## ðŸ“ˆ Expected Outcomes

- **Classification Accuracy**: Target >95% on test set
- **Recall (Critical for medical)**: >98% (minimize false negatives)
- **Precision**: >92% (minimize false positives)
- **Model Convergence**: Smooth loss decrease during training

## ðŸŽ¯ Business Impact

- **Medical Application**: Support doctors in early cancer detection
- **False Negative Cost**: Minimized through high recall optimization
- **Interpretability**: Understanding feature importance for diagnosis
- **Scalability**: Model can be deployed for screening programs

---

**Project Type**: Binary Classification with Neural Networks
**Domain**: Medical Diagnosis / Healthcare AI
**Status**: In Progress ðŸ”„
**Last Updated**: February 2026